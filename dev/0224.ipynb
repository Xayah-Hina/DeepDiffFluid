{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-24T03:33:45.385957Z",
     "start_time": "2025-02-24T03:33:40.901491Z"
    }
   },
   "source": [
    "import os, sys, logging, argparse, pickle, glob, random, pylab, time\n",
    "from tqdm import tqdm\n",
    "from phi.torch.flow import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:38:52.659060Z",
     "start_time": "2025-02-24T03:38:52.655267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# math.seed(42) # phiflow seed\n",
    "math.set_global_precision(32) # single precision\n",
    "\n",
    "USE_CPU = 0\n",
    "TORCH.set_default_device(\"GPU\")\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "if USE_CPU > 0:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)\n",
    "print(\"Using device: \"+str(device))"
   ],
   "id": "710e6d317ffa39a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:40:17.989817Z",
     "start_time": "2025-02-24T03:40:17.984431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RE_FAC_SOL = 10/(128*128) # factor to compensate for the original scaling from the original solver-in-the-loop paper\n",
    "\n",
    "class KarmanFlow():\n",
    "    def __init__(self, domain):\n",
    "        self.domain = domain\n",
    "\n",
    "        self.vel_BcMask = self.domain.staggered_grid( HardGeometryMask( Box(y=(None, 5), x=None) ) )\n",
    "\n",
    "        self.inflow = self.domain.scalar_grid(Box(y=(5,10), x=(25,75)) ) # scale with domain if necessary!\n",
    "        self.obstacles = [Obstacle(Sphere(center=tensor([50, 50], channel(vector=\"y,x\")), radius=10))]\n",
    "\n",
    "    def step(self, marker_in, velocity_in, Re, res, buoyancy_factor=0, dt=1.0):\n",
    "        velocity = velocity_in\n",
    "        marker   = marker_in\n",
    "        Re_phiflow = Re / RE_FAC_SOL # rescale for phiflow\n",
    "\n",
    "        # viscosity\n",
    "        velocity = phi.flow.diffuse.explicit(u=velocity, diffusivity=1.0/Re_phiflow*dt*res*res, dt=dt)\n",
    "\n",
    "        # inflow boundary conditions\n",
    "        velocity = velocity*(1.0 - self.vel_BcMask) + self.vel_BcMask * (1,0)\n",
    "\n",
    "        # advection\n",
    "        marker = advect.semi_lagrangian(marker+ 1. * self.inflow, velocity, dt=dt)\n",
    "        velocity = advected_velocity = advect.semi_lagrangian(velocity, velocity, dt=dt)\n",
    "\n",
    "        # mass conservation (pressure solve)\n",
    "        pressure = None\n",
    "        velocity, pressure = fluid.make_incompressible(velocity, self.obstacles)\n",
    "        self.solve_info = { 'pressure': pressure, 'advected_velocity': advected_velocity }\n",
    "\n",
    "        return [marker, velocity]\n",
    "\n"
   ],
   "id": "2058f8f33f2db5f2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:40:24.356070Z",
     "start_time": "2025-02-24T03:40:24.117138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layers = [32,32,32] # small\n",
    "#layers = [32,48,48,48,32] # uncomment for a somewhat larger and deeper network\n",
    "#network = conv_net(in_channels=3,out_channels=2,layers=layers) # a simpler variant\n",
    "network = res_net(in_channels=3,out_channels=2,layers=layers)\n",
    "print(network)\n",
    "\n",
    "# reinit\n",
    "import torch.nn as nn\n",
    "for m in network.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.1)\n",
    "\n",
    "print(\"Total number of trainable parameters: \"+ str( sum(p.numel() for p in network.parameters()) ))"
   ],
   "id": "50622ae966c89700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (Res_in): ResNetBlock(\n",
      "    (sample_input): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn_sample): Identity()\n",
      "    (bn1): Identity()\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): Identity()\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (Res1): ResNetBlock(\n",
      "    (sample_input): Identity()\n",
      "    (bn_sample): Identity()\n",
      "    (bn1): Identity()\n",
      "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): Identity()\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (Res2): ResNetBlock(\n",
      "    (sample_input): Identity()\n",
      "    (bn_sample): Identity()\n",
      "    (bn1): Identity()\n",
      "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): Identity()\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (Res_out): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Total number of trainable parameters: 47330\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:40:30.586441Z",
     "start_time": "2025-02-24T03:40:30.581230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_phiflow(batch):\n",
    "    vx = batch[:,1,:-1,:-1]\n",
    "    vy = batch[:,2,:,:] # fine\n",
    "\n",
    "    #print(\"v_dims \"+str([vx.shape,vy.shape])) # example for debugging\n",
    "    # v_dims should be vx [torch.Size([B, 64, 31]),  vy torch.Size([B, 65, 32])]\n",
    "\n",
    "    vel = domain.staggered_grid( math.stack( [\n",
    "        math.tensor(vy, math.batch('batch'), math.spatial('y, x')),\n",
    "        math.tensor(vx, math.batch('batch'), math.spatial('y, x')),\n",
    "    ], math.dual(vector=\"y,x\")\n",
    "    ) )\n",
    "    return vel\n",
    "\n",
    "def to_pytorch(marker_vel, Re):\n",
    "    # align the sides the staggered velocity grid making its size the same as the centered grid\n",
    "    grid = math.stack(\n",
    "        [\n",
    "            math.pad( marker_vel[1].vector['x'].values, {'x':(0,1)} , math.extrapolation.ZERO), # x component\n",
    "            marker_vel[1].vector['y'].y[:-1].values,                                            # y component\n",
    "            math.ones(marker_vel[0].shape)*Re                                                   # constant Re\n",
    "        ],\n",
    "        math.channel('channels')\n",
    "    ).native(order='batch,channels,y,x')\n",
    "    return grid\n",
    "\n",
    "def to_solver(inputs):\n",
    "    marker_in = inputs[:,0,:-1,:]\n",
    "    marker_in = domain.scalar_grid( math.tensor(marker_in, math.batch('batch'), math.spatial('y, x')) )\n",
    "    v_in = to_phiflow(inputs)\n",
    "    Re = math.tensor(inputs[0,3, 0,0].detach()) # Scalar , get first index 0,0\n",
    "\n",
    "    Re_norm = (Re - math.tensor(DATA_RE_MEAN)) / math.tensor(DATA_RE_STD)\n",
    "    Re_norm = float(Re_norm.native().detach()) # we just need a single number\n",
    "\n",
    "    return marker_in, v_in, Re, Re_norm\n"
   ],
   "id": "628f117ade00c21b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:41:03.148307Z",
     "start_time": "2025-02-24T03:41:02.240530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "optimizer = adam(network, LEARNING_RATE)\n",
    "\n",
    "# one of the most crucial parameters: how many simulation steps to look into the future in each training step\n",
    "MSTEPS = 4\n",
    "\n",
    "BATCH_SIZE = 3"
   ],
   "id": "58d7caa4723a29fe",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:41:31.007329Z",
     "start_time": "2025-02-24T03:41:08.517282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pbdl\n",
    "import pbdl.torch.loader\n",
    "\n",
    "dataloader = pbdl.torch.loader.Dataloader(\"solver-in-the-loop-wake-flow\", MSTEPS, shuffle=True, sel_sims=[0,1,2,3,4,5],\n",
    "                                          batch_size=BATCH_SIZE, normalize_const=\"std\", normalize_data=\"std\", intermediate_time_steps=True)\n",
    "\n",
    "# workaround for using un-normalized and normalized values in one script:\n",
    "#    save the normalization constants of the Reynolds number conditioning , then turn off (norm=None);\n",
    "#    the Re values will be normalized manually later on\n",
    "DATA_RE_MEAN = dataloader.dataset.norm_strat_const.const_mean[0][0]\n",
    "DATA_RE_STD  = dataloader.dataset.norm_strat_const.const_std[0][0]\n",
    "print([DATA_RE_MEAN,DATA_RE_STD])\n",
    "dataloader.dataset.norm_strat_const = None\n",
    "dataloader.dataset.norm_strat_data = None"
   ],
   "id": "6e36a78641342922",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[Kdownload completed\t ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[38;5;240m\u001B[96m 100%\u001B[0m6m\u001B[96m\u001B[96m\u001B[96m\u001B[96m\u001B[96m\n",
      "\u001B[96m\u001B[1mSuccess:\u001B[22m Loaded solver-in-the-loop-wake-flow with 6 simulations (6 selected) and 496 samples each.\u001B[0m\n",
      "\u001B[1mInfo:\u001B[22m No precomputed normalization data found (or not complete). Calculating data...\u001B[0m\n",
      "[np.float64(1025.390625), np.float64(1057.4417884622908)]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:42:21.135892Z",
     "start_time": "2025-02-24T03:42:20.935200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is the actual resolution in terms of cells for phiflow (not too crucial)\n",
    "SOURCE_RES = [64,32]\n",
    "\n",
    "# this is the physical size in terms of abstract units for the bounding box of the domain (it's important for conversions between computational and physical units)\n",
    "LENGTH = 100.\n",
    "\n",
    "# for readability\n",
    "from phi.physics._boundaries import Domain, OPEN, STICKY as CLOSED\n",
    "\n",
    "BNDS = {\n",
    "    'y':(phi.physics._boundaries.OPEN,  phi.physics._boundaries.OPEN) ,\n",
    "    'x':(phi.physics._boundaries.STICKY,phi.physics._boundaries.STICKY)\n",
    "}\n",
    "\n",
    "domain = phi.physics._boundaries.Domain(y=SOURCE_RES[0], x=SOURCE_RES[1], boundaries=BNDS, bounds=Box(y=2*LENGTH, x=LENGTH))\n",
    "simulator = KarmanFlow(domain=domain)"
   ],
   "id": "94c9f4be07a7cdc5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\4265755707.py:8: FutureWarning: Domain (phi.physics._boundaries) is deprecated and will be removed in a future release.\n",
      "Please create grids directly, replacing the domain with a dict, e.g.\n",
      "    domain = dict(x=64, y=128, bounds=Box(x=1, y=1))\n",
      "    grid = CenteredGrid(0, **domain)\n",
      "  from phi.physics._boundaries import Domain, OPEN, STICKY as CLOSED\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\4265755707.py:15: DeprecationWarning: Domain is deprecated and will be removed in a future release. Use a dict instead, e.g. CenteredGrid(values, extrapolation, **domain_dict)\n",
      "  domain = phi.physics._boundaries.Domain(y=SOURCE_RES[0], x=SOURCE_RES[1], boundaries=BNDS, bounds=Box(y=2*LENGTH, x=LENGTH))\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\4265755707.py:15: FutureWarning: Domain is deprecated and will be removed in a future release. Use a dict instead, e.g. CenteredGrid(values, extrapolation, **domain_dict)\n",
      "  domain = phi.physics._boundaries.Domain(y=SOURCE_RES[0], x=SOURCE_RES[1], boundaries=BNDS, bounds=Box(y=2*LENGTH, x=LENGTH))\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\2052032387.py:7: DeprecationWarning: HardGeometryMask and SoftGeometryMask are deprecated. Use field.mask or field.resample instead.\n",
      "  self.vel_BcMask = self.domain.staggered_grid( HardGeometryMask( Box(y=(None, 5), x=None) ) )\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:42:21.548648Z",
     "start_time": "2025-02-24T03:42:21.545008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit_compile\n",
    "def simulation_step(marker,velocity,Re,resolution):\n",
    "    m,v = simulator.step(\n",
    "        marker_in=marker,\n",
    "        velocity_in=velocity,\n",
    "        Re=Re, res=resolution\n",
    "    )\n",
    "    return m,v"
   ],
   "id": "3216084fe69965c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:42:24.342056Z",
     "start_time": "2025-02-24T03:42:24.336931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_step(inputs_targets):\n",
    "    [inputs, targets] = inputs_targets\n",
    "    marker_in, v_in, Re, Re_norm = to_solver(inputs)\n",
    "    prediction = [ [marker_in,v_in] ]\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(MSTEPS):\n",
    "        m2,v2 = simulation_step(\n",
    "            marker=prediction[-1][0],\n",
    "            velocity=prediction[-1][1],\n",
    "            Re=Re, resolution=SOURCE_RES[1]\n",
    "        )\n",
    "\n",
    "        net_in = to_pytorch([m2,v2],Re_norm)\n",
    "        net_out = network(net_in)\n",
    "\n",
    "        cy = net_out[:,1,:,:] # pad y\n",
    "        cy = torch.nn.functional.pad(input=cy, pad=(0,0, 0,1), mode='constant', value=0)\n",
    "        cx = net_out[:,0,:,:-1]\n",
    "\n",
    "        v_corr = domain.staggered_grid( math.stack( [\n",
    "            math.tensor(cy, math.batch('batch'), math.spatial('y, x')),\n",
    "            math.tensor(cx, math.batch('batch'), math.spatial('y, x')),\n",
    "        ], math.dual(vector=\"y,x\")\n",
    "        ) )\n",
    "\n",
    "        prediction += [ [domain.scalar_grid(m2) , v2 + v_corr] ]\n",
    "        vdiff = prediction[-1][1] - to_phiflow(targets[:,i,...])\n",
    "        loss += field.l2_loss(vdiff)\n",
    "\n",
    "    return loss, prediction\n"
   ],
   "id": "14567603768a9067",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:44:33.432150Z",
     "start_time": "2025-02-24T03:42:26.040404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "pbar = tqdm(initial=0, total=EPOCHS*len(dataloader), ncols=96)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for b, (input_cpu, targets_cpu) in enumerate(dataloader):\n",
    "        input = torch.tensor(input_cpu, dtype=torch.float32).to(device);\n",
    "        targets = torch.tensor(targets_cpu, dtype=torch.float32).to(device)\n",
    "\n",
    "        loss, prediction = update_weights(network, optimizer, training_step, [input, targets])\n",
    "\n",
    "        pbar.set_description(\"loss \"+str(np.sum(loss.numpy(\"batch\"))), refresh=False); pbar.update(1)\n",
    "\n",
    "    torch.save(network.state_dict(), \"net-\"+str(epoch)+\".pickle\")\n",
    "\n",
    "pbar.close()"
   ],
   "id": "13fbb54748a5a01c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                  | 0/4960 [00:00<?, ?it/s]C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\3073841444.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input_cpu, dtype=torch.float32).to(device);\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\3073841444.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets_cpu, dtype=torch.float32).to(device)\n",
      "C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_optimize.py:635: UserWarning: Possible rank deficiency detected. Matrix might be singular which can lead to convergence problems. Please specify using Solve(rank_deficiency=...).\n",
      "  warnings.warn(\"Possible rank deficiency detected. Matrix might be singular which can lead to convergence problems. Please specify using Solve(rank_deficiency=...).\")\n",
      "C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py:810: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  return torch.sparse_csr_tensor(row_pointers, column_indices, values, shape, device=values.device)\n",
      "C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_optimize.py:635: UserWarning: Possible rank deficiency detected. Matrix might be singular which can lead to convergence problems. Please specify using Solve(rank_deficiency=...).\n",
      "  warnings.warn(\"Possible rank deficiency detected. Matrix might be singular which can lead to convergence problems. Please specify using Solve(rank_deficiency=...).\")\n",
      "loss 11.2373705:   0%|                                      | 1/4960 [00:08<11:22:09,  8.25s/it]C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\3073841444.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input_cpu, dtype=torch.float32).to(device);\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\3073841444.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets_cpu, dtype=torch.float32).to(device)\n",
      "loss 8.132623:   2%|▊                                      | 111/4960 [02:06<1:29:06,  1.10s/it]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\autograd\\function.py(575): apply\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(248): select_jit\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py(963): __call__\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_optimize.py(666): solve_linear\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phi\\physics\\fluid.py(156): make_incompressible\nC:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\2052032387.py(29): step\nC:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\2022291116.py(3): simulation_step\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py(256): jit_f_native\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(1124): forward\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1729): _slow_forward\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1750): _call_impl\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1739): _wrapped_call_impl\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\jit\\_trace.py(1276): trace_module\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\jit\\_trace.py(696): _trace_impl\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\jit\\_trace.py(1000): trace\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(1130): __call__\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py(310): __call__\nC:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\4240932139.py(8): training_step\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\nets.py(56): update_weights\nC:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\3073841444.py(10): <module>\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3579): run_code\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3519): run_ast_nodes\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3336): run_cell_async\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py(128): _pseudo_sync_runner\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3132): _run_cell\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3077): run_cell\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py(549): run_cell\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py(449): do_execute\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(778): execute_request\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py(362): execute_request\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(437): dispatch_shell\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(534): process_one\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(545): dispatch_queue\nC:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py(89): _run\nC:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py(2040): _run_once\nC:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py(683): run_forever\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py(205): start\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py(739): start\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\traitlets\\config\\application.py(1075): launch_instance\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel_launcher.py(18): <module>\n<frozen runpy>(88): _run_code\n<frozen runpy>(198): _run_module_as_main\nRuntimeError: KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(1179): forward\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\autograd\\function.py(575): apply\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1750): _call_impl\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1739): _wrapped_call_impl\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\_backend.py(427): call\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(1135): __call__\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py(314): __call__\n  C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\4240932139.py(8): training_step\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\nets.py(56): update_weights\n  C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\3073841444.py(10): <module>\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3579): run_code\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3519): run_ast_nodes\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3336): run_cell_async\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py(128): _pseudo_sync_runner\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3132): _run_cell\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3077): run_cell\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py(549): run_cell\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py(449): do_execute\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(778): execute_request\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py(362): execute_request\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(437): dispatch_shell\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(534): process_one\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(545): dispatch_queue\n  C:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py(89): _run\n  C:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py(2040): _run_once\n  C:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py(683): run_forever\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py(205): start\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py(739): start\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\traitlets\\config\\application.py(1075): launch_instance\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel_launcher.py(18): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(input_cpu, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39mto(device);\n\u001B[0;32m      8\u001B[0m     targets \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(targets_cpu, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 10\u001B[0m     loss, prediction \u001B[38;5;241m=\u001B[39m \u001B[43mupdate_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mset_description(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(np\u001B[38;5;241m.\u001B[39msum(loss\u001B[38;5;241m.\u001B[39mnumpy(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m))), refresh\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m); pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     14\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(network\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnet-\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(epoch)\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\nets.py:56\u001B[0m, in \u001B[0;36mupdate_weights\u001B[1;34m(net, optimizer, loss_function, check_nan, *loss_args, **loss_kwargs)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mupdate_weights\u001B[39m(net: nn\u001B[38;5;241m.\u001B[39mModule, optimizer: optim\u001B[38;5;241m.\u001B[39mOptimizer, loss_function: Callable, \u001B[38;5;241m*\u001B[39mloss_args, check_nan\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mloss_kwargs):\n\u001B[0;32m     55\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 56\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mloss_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mloss_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mloss_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m     loss \u001B[38;5;241m=\u001B[39m output[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m output\n\u001B[0;32m     58\u001B[0m     loss\u001B[38;5;241m.\u001B[39msum\u001B[38;5;241m.\u001B[39mbackward()\n",
      "Cell \u001B[1;32mIn[14], line 8\u001B[0m, in \u001B[0;36mtraining_step\u001B[1;34m(inputs_targets)\u001B[0m\n\u001B[0;32m      5\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(MSTEPS):\n\u001B[1;32m----> 8\u001B[0m     m2,v2 \u001B[38;5;241m=\u001B[39m \u001B[43msimulation_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmarker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprediction\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvelocity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprediction\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43mRe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSOURCE_RES\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     net_in \u001B[38;5;241m=\u001B[39m to_pytorch([m2,v2],Re_norm)\n\u001B[0;32m     15\u001B[0m     net_out \u001B[38;5;241m=\u001B[39m network(net_in)\n",
      "File \u001B[1;32m~\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py:314\u001B[0m, in \u001B[0;36mJitFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    312\u001B[0m     buffer_config \u001B[38;5;241m=\u001B[39m out_key\u001B[38;5;241m.\u001B[39mbuffer_config\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 314\u001B[0m     all_natives \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraces\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrace_index\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnatives\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# call compiled function\u001B[39;00m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;66;03m# --- record buffers ---\u001B[39;00m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m buffer_config:\n",
      "File \u001B[1;32m~\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py:1135\u001B[0m, in \u001B[0;36mJITFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1133\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautograd_function_call_counts \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautograd_function_calls), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNot all custom-gradient functions were called during tracing! Nested custom gradients are not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m choose_backend\n\u001B[1;32m-> 1135\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mchoose_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraced\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun jit-compiled \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\_backend.py:427\u001B[0m, in \u001B[0;36mBackend.call\u001B[1;34m(self, f, name, *args)\u001B[0m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, f: Callable, \u001B[38;5;241m*\u001B[39margs, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    419\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    420\u001B[0m \u001B[38;5;124;03m    Calls `f(*args)` and returns the result.\u001B[39;00m\n\u001B[0;32m    421\u001B[0m \u001B[38;5;124;03m    This method may be used to register internal calls with the profiler.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    425\u001B[0m \u001B[38;5;124;03m        choose_backend(key).call(custom_function, *args)\u001B[39;00m\n\u001B[0;32m    426\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 427\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\autograd\\function.py(575): apply\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(248): select_jit\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py(963): __call__\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_optimize.py(666): solve_linear\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phi\\physics\\fluid.py(156): make_incompressible\nC:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\2052032387.py(29): step\nC:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\2022291116.py(3): simulation_step\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py(256): jit_f_native\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(1124): forward\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1729): _slow_forward\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1750): _call_impl\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1739): _wrapped_call_impl\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\jit\\_trace.py(1276): trace_module\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\jit\\_trace.py(696): _trace_impl\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\jit\\_trace.py(1000): trace\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(1130): __call__\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py(310): __call__\nC:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\4240932139.py(8): training_step\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\nets.py(56): update_weights\nC:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\3073841444.py(10): <module>\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3579): run_code\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3519): run_ast_nodes\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3336): run_cell_async\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py(128): _pseudo_sync_runner\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3132): _run_cell\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3077): run_cell\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py(549): run_cell\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py(449): do_execute\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(778): execute_request\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py(362): execute_request\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(437): dispatch_shell\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(534): process_one\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(545): dispatch_queue\nC:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py(89): _run\nC:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py(2040): _run_once\nC:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py(683): run_forever\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py(205): start\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py(739): start\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\traitlets\\config\\application.py(1075): launch_instance\nC:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel_launcher.py(18): <module>\n<frozen runpy>(88): _run_code\n<frozen runpy>(198): _run_module_as_main\nRuntimeError: KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(1179): forward\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\autograd\\function.py(575): apply\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1750): _call_impl\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1739): _wrapped_call_impl\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\_backend.py(427): call\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py(1135): __call__\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_functional.py(314): __call__\n  C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\4240932139.py(8): training_step\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\nets.py(56): update_weights\n  C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_22524\\3073841444.py(10): <module>\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3579): run_code\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3519): run_ast_nodes\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3336): run_cell_async\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py(128): _pseudo_sync_runner\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3132): _run_cell\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py(3077): run_cell\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py(549): run_cell\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py(449): do_execute\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(778): execute_request\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py(362): execute_request\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(437): dispatch_shell\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(534): process_one\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py(545): dispatch_queue\n  C:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py(89): _run\n  C:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py(2040): _run_once\n  C:\\Users\\xayah\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py(683): run_forever\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py(205): start\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py(739): start\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\traitlets\\config\\application.py(1075): launch_instance\n  C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\ipykernel_launcher.py(18): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "del dataloader # close hdf5 file handle\n",
    "\n",
    "# get new & unseen test data\n",
    "dataloader_test = pbdl.torch.loader.Dataloader(\"solver-in-the-loop-wake-flow\", 200, batch_size=1, shuffle=True, sel_sims=[6,7,8,9],\n",
    "                                               normalize=False, intermediate_time_steps=True)"
   ],
   "id": "7122713becc82cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# optionally load\n",
    "if False:\n",
    "    fn = \"net-\"+str(EPOCHS-1)+\".pickle\" # load last\n",
    "    network.load_state_dict(torch.load(fn, map_location=device, weights_only=True))\n",
    "    print(\"Loaded \"+fn)"
   ],
   "id": "3304f7de1e1a06ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_sim(inputs, targets, steps, network=None):\n",
    "    marker_in, v_in, Re, Re_norm = to_solver(inputs)\n",
    "\n",
    "    simtype = \"With corr.\"\n",
    "    if (network==None): simtype = \"Sim. only\"\n",
    "    print(\"Running test with Re=\"+str(Re)+\", \"+simtype)\n",
    "\n",
    "    prediction = [ [marker_in,v_in] ]\n",
    "    correction = [ [marker_in,v_in] ]\n",
    "    refs = [ v_in ]\n",
    "    errors = []\n",
    "\n",
    "    for i in tqdm(range(steps), desc=simtype, ncols = 64):\n",
    "        marker_sim,v_sim = simulation_step(\n",
    "            marker=prediction[-1][0],\n",
    "            velocity=prediction[-1][1],\n",
    "            Re=Re, resolution=SOURCE_RES[1]  # take Re from constant field\n",
    "        )\n",
    "\n",
    "        if network: # run hybrid solver with trained Neural op\n",
    "            net_in = to_pytorch([marker_sim,v_sim],Re_norm)\n",
    "            net_out = network(net_in)\n",
    "\n",
    "            cy = net_out[:,1,:,:] # pad y\n",
    "            cy = torch.nn.functional.pad(input=cy, pad=(0,0, 0,1), mode='constant', value=0)\n",
    "            cx = net_out[:,0,:,:-1]\n",
    "\n",
    "            v_corr = domain.staggered_grid( math.stack( [\n",
    "                math.tensor(cy, math.batch('batch'), math.spatial('y, x')),\n",
    "                math.tensor(cx, math.batch('batch'), math.spatial('y, x')),\n",
    "            ], math.dual(vector=\"y,x\")\n",
    "            ) )\n",
    "\n",
    "            prediction += [ [domain.scalar_grid(marker_sim) , v_sim + v_corr] ]\n",
    "            correction += [ [domain.scalar_grid(marker_sim) , v_corr] ]\n",
    "\n",
    "        else: # only low-fidelity solver\n",
    "            prediction += [ [domain.scalar_grid(marker_sim) , v_sim ] ]\n",
    "\n",
    "        refs += [to_phiflow(targets[:,i,...])]\n",
    "        vdiff = prediction[i][1] - refs[-1]\n",
    "\n",
    "        error_phi = field.l1_loss(vdiff)\n",
    "        errors += [float( error_phi.native(\"batch\")[0] / field.l1_loss(refs[-1]).native(\"batch\")[0] )]\n",
    "\n",
    "    return errors, prediction, refs, correction\n"
   ],
   "id": "8e6eacadcb7190a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# get a sample\n",
    "(input_cpu, targets_cpu) = next(iter(dataloader_test))\n",
    "input = torch.tensor(input_cpu, dtype=torch.float32).to(device)\n",
    "targets = torch.tensor(targets_cpu, dtype=torch.float32).to(device)\n",
    "print(\"Re \",math.tensor(input[0,3, 0,0].detach()))"
   ],
   "id": "9e55d63c932b981e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ROLLOUT_STEPS = 100\n",
    "\n",
    "err_lowfid_only, prediction_lowfid_only, refs, _   = run_sim(input, targets, ROLLOUT_STEPS)\n",
    "err_corrected,   prediction_corrected  , _ , corrs = run_sim(input, targets, ROLLOUT_STEPS, network)\n",
    "print(\"\\n Rel. L2 errors: low-fidelity:\", float(np.mean(err_lowfid_only)),\" corrected:\", float(np.mean(err_corrected)) )"
   ],
   "id": "ddfb304e0739ef41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig = pylab.figure().gca()\n",
    "pltx = np.linspace(0,ROLLOUT_STEPS-1,ROLLOUT_STEPS)\n",
    "fig.plot(pltx, err_lowfid_only, lw=2, color='mediumblue', label='Source')\n",
    "fig.plot(pltx, err_corrected,   lw=2, color='green', label='Hybrid')\n",
    "pylab.xlabel('Time step'); pylab.ylabel('Relative L2 error'); fig.legend()\n"
   ],
   "id": "9da3e905df7f8fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# which step from which batch to show , by default shows last step from first case\n",
    "STEP = ROLLOUT_STEPS\n",
    "BATCH = 0\n",
    "NUM_SHOW = 4\n",
    "PRINT_STATS = False # optional, print statistics\n",
    "\n",
    "fig, axes = pylab.subplots(1, 4, figsize=(16, 5))\n",
    "i = 0\n",
    "\n",
    "v = refs[STEP].staggered_tensor().numpy('batch,y,x,vector')[BATCH,:,:,0]\n",
    "if PRINT_STATS: print([\"reference \", BATCH, i, np.mean(v),  np.min(v) ,  np.max(v)])\n",
    "axes[i].set_title(f\"Ref\")\n",
    "im=axes[i].imshow( v , origin='lower', cmap='magma') ;\n",
    "pylab.colorbar(im) ; i=i+1; vy_ref=v\n",
    "\n",
    "v = prediction_lowfid_only[STEP][1].staggered_tensor().numpy('batch,y,x,vector')[BATCH,:,:,0]\n",
    "if PRINT_STATS: print([\"low-fid. \", BATCH, i, np.mean(v),  np.min(v) ,  np.max(v)])\n",
    "axes[i].set_title(f\"Low-fid.\")\n",
    "im=axes[i].imshow( v , origin='lower', cmap='magma') ;\n",
    "pylab.colorbar(im) ; i=i+1; vy_lowfid=v\n",
    "\n",
    "v = prediction_corrected[STEP][1].staggered_tensor().numpy('batch,y,x,vector')[BATCH,:,:,0]\n",
    "if PRINT_STATS: print([\"corrected\", BATCH, i, np.mean(v),  np.min(v) ,  np.max(v)])\n",
    "axes[i].set_title(f\"Corr.\")\n",
    "im=axes[i].imshow( v , origin='lower', cmap='magma') ;\n",
    "pylab.colorbar(im) ; i=i+1; vy_corr=v\n",
    "\n",
    "# show error side by side\n",
    "err_lf   = vy_ref - vy_lowfid\n",
    "err_corr = vy_ref - vy_corr\n",
    "v = np.concatenate([err_lf,err_corr], axis=1)\n",
    "axes[i].set_title(f\" Errors: Low-fid & Learned\")\n",
    "im=axes[i].imshow( v , origin='lower', cmap='cividis') ;\n",
    "pylab.colorbar(im) ; i=i+1\n",
    "\n",
    "pylab.tight_layout()"
   ],
   "id": "117652e97ace63a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
