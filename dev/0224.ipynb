{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:52.251607Z",
     "start_time": "2025-02-24T04:02:50.133777Z"
    }
   },
   "source": [
    "import os, sys, logging, argparse, pickle, glob, random, pylab, time\n",
    "from tqdm import tqdm\n",
    "from phi.torch.flow import *\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# math.seed(42) # phiflow seed\n",
    "math.set_global_precision(32) # single precision\n",
    "\n",
    "USE_CPU = 0\n",
    "TORCH.set_default_device(\"GPU\")\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "if USE_CPU > 0:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)\n",
    "print(\"Using device: \"+str(device))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:52.262681Z",
     "start_time": "2025-02-24T04:02:52.257507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RE_FAC_SOL = 10/(128*128) # factor to compensate for the original scaling from the original solver-in-the-loop paper\n",
    "\n",
    "class KarmanFlow():\n",
    "    def __init__(self, domain):\n",
    "        self.domain = domain\n",
    "\n",
    "        self.vel_BcMask = self.domain.staggered_grid( HardGeometryMask( Box(y=(None, 5), x=None) ) )\n",
    "\n",
    "        self.inflow = self.domain.scalar_grid(Box(y=(5,10), x=(25,75)) ) # scale with domain if necessary!\n",
    "        self.obstacles = [Obstacle(Sphere(center=tensor([50, 50], channel(vector=\"y,x\")), radius=10))]\n",
    "\n",
    "    def step(self, marker_in, velocity_in, Re, res, buoyancy_factor=0, dt=1.0):\n",
    "        velocity = velocity_in\n",
    "        marker   = marker_in\n",
    "        Re_phiflow = Re / RE_FAC_SOL # rescale for phiflow\n",
    "\n",
    "        # viscosity\n",
    "        velocity = phi.flow.diffuse.explicit(u=velocity, diffusivity=1.0/Re_phiflow*dt*res*res, dt=dt)\n",
    "\n",
    "        # inflow boundary conditions\n",
    "        velocity = velocity*(1.0 - self.vel_BcMask) + self.vel_BcMask * (1,0)\n",
    "\n",
    "        # advection\n",
    "        marker = advect.semi_lagrangian(marker+ 1. * self.inflow, velocity, dt=dt)\n",
    "        velocity = advected_velocity = advect.semi_lagrangian(velocity, velocity, dt=dt)\n",
    "\n",
    "        # mass conservation (pressure solve)\n",
    "        pressure = None\n",
    "        velocity, pressure = fluid.make_incompressible(velocity, self.obstacles)\n",
    "        self.solve_info = { 'pressure': pressure, 'advected_velocity': advected_velocity }\n",
    "\n",
    "        return [marker, velocity]\n",
    "\n"
   ],
   "id": "2058f8f33f2db5f2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:52.483562Z",
     "start_time": "2025-02-24T04:02:52.366203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layers = [32,32,32] # small\n",
    "#layers = [32,48,48,48,32] # uncomment for a somewhat larger and deeper network\n",
    "#network = conv_net(in_channels=3,out_channels=2,layers=layers) # a simpler variant\n",
    "network = res_net(in_channels=3,out_channels=2,layers=layers)\n",
    "print(network)\n",
    "\n",
    "# reinit\n",
    "import torch.nn as nn\n",
    "for m in network.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.1)\n",
    "\n",
    "print(\"Total number of trainable parameters: \"+ str( sum(p.numel() for p in network.parameters()) ))"
   ],
   "id": "50622ae966c89700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (Res_in): ResNetBlock(\n",
      "    (sample_input): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn_sample): Identity()\n",
      "    (bn1): Identity()\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): Identity()\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (Res1): ResNetBlock(\n",
      "    (sample_input): Identity()\n",
      "    (bn_sample): Identity()\n",
      "    (bn1): Identity()\n",
      "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): Identity()\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (Res2): ResNetBlock(\n",
      "    (sample_input): Identity()\n",
      "    (bn_sample): Identity()\n",
      "    (bn1): Identity()\n",
      "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): Identity()\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (Res_out): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Total number of trainable parameters: 47330\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:52.497897Z",
     "start_time": "2025-02-24T04:02:52.491511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_phiflow(batch):\n",
    "    vx = batch[:,1,:-1,:-1]\n",
    "    vy = batch[:,2,:,:] # fine\n",
    "\n",
    "    #print(\"v_dims \"+str([vx.shape,vy.shape])) # example for debugging\n",
    "    # v_dims should be vx [torch.Size([B, 64, 31]),  vy torch.Size([B, 65, 32])]\n",
    "\n",
    "    vel = domain.staggered_grid( math.stack( [\n",
    "        math.tensor(vy, math.batch('batch'), math.spatial('y, x')),\n",
    "        math.tensor(vx, math.batch('batch'), math.spatial('y, x')),\n",
    "    ], math.dual(vector=\"y,x\")\n",
    "    ) )\n",
    "    return vel\n",
    "\n",
    "def to_pytorch(marker_vel, Re):\n",
    "    # align the sides the staggered velocity grid making its size the same as the centered grid\n",
    "    grid = math.stack(\n",
    "        [\n",
    "            math.pad( marker_vel[1].vector['x'].values, {'x':(0,1)} , math.extrapolation.ZERO), # x component\n",
    "            marker_vel[1].vector['y'].y[:-1].values,                                            # y component\n",
    "            math.ones(marker_vel[0].shape)*Re                                                   # constant Re\n",
    "        ],\n",
    "        math.channel('channels')\n",
    "    ).native(order='batch,channels,y,x')\n",
    "    return grid\n",
    "\n",
    "def to_solver(inputs):\n",
    "    marker_in = inputs[:,0,:-1,:]\n",
    "    marker_in = domain.scalar_grid( math.tensor(marker_in, math.batch('batch'), math.spatial('y, x')) )\n",
    "    v_in = to_phiflow(inputs)\n",
    "    Re = math.tensor(inputs[0,3, 0,0].detach()) # Scalar , get first index 0,0\n",
    "\n",
    "    Re_norm = (Re - math.tensor(DATA_RE_MEAN)) / math.tensor(DATA_RE_STD)\n",
    "    Re_norm = float(Re_norm.native().detach()) # we just need a single number\n",
    "\n",
    "    return marker_in, v_in, Re, Re_norm\n"
   ],
   "id": "628f117ade00c21b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:53.333673Z",
     "start_time": "2025-02-24T04:02:52.516923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "optimizer = adam(network, LEARNING_RATE)\n",
    "\n",
    "# one of the most crucial parameters: how many simulation steps to look into the future in each training step\n",
    "MSTEPS = 4\n",
    "\n",
    "BATCH_SIZE = 3"
   ],
   "id": "58d7caa4723a29fe",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:59.788026Z",
     "start_time": "2025-02-24T04:02:53.338643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pbdl\n",
    "import pbdl.torch.loader\n",
    "\n",
    "dataloader = pbdl.torch.loader.Dataloader(\"solver-in-the-loop-wake-flow\", MSTEPS, shuffle=True, sel_sims=[0,1,2,3,4,5],\n",
    "                                          batch_size=BATCH_SIZE, normalize_const=\"std\", normalize_data=\"std\", intermediate_time_steps=True)\n",
    "\n",
    "# workaround for using un-normalized and normalized values in one script:\n",
    "#    save the normalization constants of the Reynolds number conditioning , then turn off (norm=None);\n",
    "#    the Re values will be normalized manually later on\n",
    "DATA_RE_MEAN = dataloader.dataset.norm_strat_const.const_mean[0][0]\n",
    "DATA_RE_STD  = dataloader.dataset.norm_strat_const.const_std[0][0]\n",
    "print([DATA_RE_MEAN,DATA_RE_STD])\n",
    "dataloader.dataset.norm_strat_const = None\n",
    "dataloader.dataset.norm_strat_data = None"
   ],
   "id": "6e36a78641342922",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[Kdownload completed\t ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[38;5;240m\u001B[96m 100%\u001B[0m6m\u001B[96m\u001B[96m\u001B[96m\u001B[96m\u001B[96m\n",
      "\u001B[96m\u001B[1mSuccess:\u001B[22m Loaded solver-in-the-loop-wake-flow with 6 simulations (6 selected) and 496 samples each.\u001B[0m\n",
      "[np.float64(1025.390625), np.float64(1057.4417884622908)]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:59.872072Z",
     "start_time": "2025-02-24T04:02:59.796391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is the actual resolution in terms of cells for phiflow (not too crucial)\n",
    "SOURCE_RES = [64,32]\n",
    "\n",
    "# this is the physical size in terms of abstract units for the bounding box of the domain (it's important for conversions between computational and physical units)\n",
    "LENGTH = 100.\n",
    "\n",
    "# for readability\n",
    "from phi.physics._boundaries import Domain, OPEN, STICKY as CLOSED\n",
    "\n",
    "BNDS = {\n",
    "    'y':(phi.physics._boundaries.OPEN,  phi.physics._boundaries.OPEN) ,\n",
    "    'x':(phi.physics._boundaries.STICKY,phi.physics._boundaries.STICKY)\n",
    "}\n",
    "\n",
    "domain = phi.physics._boundaries.Domain(y=SOURCE_RES[0], x=SOURCE_RES[1], boundaries=BNDS, bounds=Box(y=2*LENGTH, x=LENGTH))\n",
    "simulator = KarmanFlow(domain=domain)"
   ],
   "id": "94c9f4be07a7cdc5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_26868\\4265755707.py:8: FutureWarning: Domain (phi.physics._boundaries) is deprecated and will be removed in a future release.\n",
      "Please create grids directly, replacing the domain with a dict, e.g.\n",
      "    domain = dict(x=64, y=128, bounds=Box(x=1, y=1))\n",
      "    grid = CenteredGrid(0, **domain)\n",
      "  from phi.physics._boundaries import Domain, OPEN, STICKY as CLOSED\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_26868\\4265755707.py:15: DeprecationWarning: Domain is deprecated and will be removed in a future release. Use a dict instead, e.g. CenteredGrid(values, extrapolation, **domain_dict)\n",
      "  domain = phi.physics._boundaries.Domain(y=SOURCE_RES[0], x=SOURCE_RES[1], boundaries=BNDS, bounds=Box(y=2*LENGTH, x=LENGTH))\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_26868\\4265755707.py:15: FutureWarning: Domain is deprecated and will be removed in a future release. Use a dict instead, e.g. CenteredGrid(values, extrapolation, **domain_dict)\n",
      "  domain = phi.physics._boundaries.Domain(y=SOURCE_RES[0], x=SOURCE_RES[1], boundaries=BNDS, bounds=Box(y=2*LENGTH, x=LENGTH))\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_26868\\2052032387.py:7: DeprecationWarning: HardGeometryMask and SoftGeometryMask are deprecated. Use field.mask or field.resample instead.\n",
      "  self.vel_BcMask = self.domain.staggered_grid( HardGeometryMask( Box(y=(None, 5), x=None) ) )\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:59.896335Z",
     "start_time": "2025-02-24T04:02:59.892909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit_compile\n",
    "def simulation_step(marker,velocity,Re,resolution):\n",
    "    m,v = simulator.step(\n",
    "        marker_in=marker,\n",
    "        velocity_in=velocity,\n",
    "        Re=Re, res=resolution\n",
    "    )\n",
    "    return m,v"
   ],
   "id": "3216084fe69965c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:02:59.942479Z",
     "start_time": "2025-02-24T04:02:59.937432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_step(inputs_targets):\n",
    "    [inputs, targets] = inputs_targets\n",
    "    marker_in, v_in, Re, Re_norm = to_solver(inputs)\n",
    "    prediction = [ [marker_in,v_in] ]\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(MSTEPS):\n",
    "        m2,v2 = simulation_step(\n",
    "            marker=prediction[-1][0],\n",
    "            velocity=prediction[-1][1],\n",
    "            Re=Re, resolution=SOURCE_RES[1]\n",
    "        )\n",
    "\n",
    "        net_in = to_pytorch([m2,v2],Re_norm)\n",
    "        net_out = network(net_in)\n",
    "\n",
    "        cy = net_out[:,1,:,:] # pad y\n",
    "        cy = torch.nn.functional.pad(input=cy, pad=(0,0, 0,1), mode='constant', value=0)\n",
    "        cx = net_out[:,0,:,:-1]\n",
    "\n",
    "        v_corr = domain.staggered_grid( math.stack( [\n",
    "            math.tensor(cy, math.batch('batch'), math.spatial('y, x')),\n",
    "            math.tensor(cx, math.batch('batch'), math.spatial('y, x')),\n",
    "        ], math.dual(vector=\"y,x\")\n",
    "        ) )\n",
    "\n",
    "        prediction += [ [domain.scalar_grid(m2) , v2 + v_corr] ]\n",
    "        vdiff = prediction[-1][1] - to_phiflow(targets[:,i,...])\n",
    "        loss += field.l2_loss(vdiff)\n",
    "\n",
    "    return loss, prediction\n"
   ],
   "id": "14567603768a9067",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-24T04:03:00.021267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "pbar = tqdm(initial=0, total=EPOCHS*len(dataloader), ncols=96)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for b, (input_cpu, targets_cpu) in enumerate(dataloader):\n",
    "        input = torch.tensor(input_cpu, dtype=torch.float32).to(device);\n",
    "        targets = torch.tensor(targets_cpu, dtype=torch.float32).to(device)\n",
    "\n",
    "        loss, prediction = update_weights(network, optimizer, training_step, [input, targets])\n",
    "\n",
    "        pbar.set_description(\"loss \"+str(np.sum(loss.numpy(\"batch\"))), refresh=False); pbar.update(1)\n",
    "\n",
    "    torch.save(network.state_dict(), \"net-\"+str(epoch)+\".pickle\")\n",
    "\n",
    "pbar.close()"
   ],
   "id": "13fbb54748a5a01c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                  | 0/4960 [00:00<?, ?it/s]C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_26868\\3073841444.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input_cpu, dtype=torch.float32).to(device);\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_26868\\3073841444.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets_cpu, dtype=torch.float32).to(device)\n",
      "C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_optimize.py:635: UserWarning: Possible rank deficiency detected. Matrix might be singular which can lead to convergence problems. Please specify using Solve(rank_deficiency=...).\n",
      "  warnings.warn(\"Possible rank deficiency detected. Matrix might be singular which can lead to convergence problems. Please specify using Solve(rank_deficiency=...).\")\n",
      "C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\backend\\torch\\_torch_backend.py:810: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  return torch.sparse_csr_tensor(row_pointers, column_indices, values, shape, device=values.device)\n",
      "C:\\Users\\xayah\\Desktop\\DeepDiffFluid\\venv\\Lib\\site-packages\\phiml\\math\\_optimize.py:635: UserWarning: Possible rank deficiency detected. Matrix might be singular which can lead to convergence problems. Please specify using Solve(rank_deficiency=...).\n",
      "  warnings.warn(\"Possible rank deficiency detected. Matrix might be singular which can lead to convergence problems. Please specify using Solve(rank_deficiency=...).\")\n",
      "loss 13.250685:   0%|                                       | 1/4960 [00:07<10:12:27,  7.41s/it]C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_26868\\3073841444.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input_cpu, dtype=torch.float32).to(device);\n",
      "C:\\Users\\xayah\\AppData\\Local\\Temp\\ipykernel_26868\\3073841444.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets_cpu, dtype=torch.float32).to(device)\n",
      "loss 10.4999695:   0%|                                       | 8/4960 [00:15<1:47:01,  1.30s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "del dataloader # close hdf5 file handle\n",
    "\n",
    "# get new & unseen test data\n",
    "dataloader_test = pbdl.torch.loader.Dataloader(\"solver-in-the-loop-wake-flow\", 200, batch_size=1, shuffle=True, sel_sims=[6,7,8,9],\n",
    "                                               normalize=False, intermediate_time_steps=True)"
   ],
   "id": "7122713becc82cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# optionally load\n",
    "if False:\n",
    "    fn = \"net-\"+str(EPOCHS-1)+\".pickle\" # load last\n",
    "    network.load_state_dict(torch.load(fn, map_location=device, weights_only=True))\n",
    "    print(\"Loaded \"+fn)"
   ],
   "id": "3304f7de1e1a06ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_sim(inputs, targets, steps, network=None):\n",
    "    marker_in, v_in, Re, Re_norm = to_solver(inputs)\n",
    "\n",
    "    simtype = \"With corr.\"\n",
    "    if (network==None): simtype = \"Sim. only\"\n",
    "    print(\"Running test with Re=\"+str(Re)+\", \"+simtype)\n",
    "\n",
    "    prediction = [ [marker_in,v_in] ]\n",
    "    correction = [ [marker_in,v_in] ]\n",
    "    refs = [ v_in ]\n",
    "    errors = []\n",
    "\n",
    "    for i in tqdm(range(steps), desc=simtype, ncols = 64):\n",
    "        marker_sim,v_sim = simulation_step(\n",
    "            marker=prediction[-1][0],\n",
    "            velocity=prediction[-1][1],\n",
    "            Re=Re, resolution=SOURCE_RES[1]  # take Re from constant field\n",
    "        )\n",
    "\n",
    "        if network: # run hybrid solver with trained Neural op\n",
    "            net_in = to_pytorch([marker_sim,v_sim],Re_norm)\n",
    "            net_out = network(net_in)\n",
    "\n",
    "            cy = net_out[:,1,:,:] # pad y\n",
    "            cy = torch.nn.functional.pad(input=cy, pad=(0,0, 0,1), mode='constant', value=0)\n",
    "            cx = net_out[:,0,:,:-1]\n",
    "\n",
    "            v_corr = domain.staggered_grid( math.stack( [\n",
    "                math.tensor(cy, math.batch('batch'), math.spatial('y, x')),\n",
    "                math.tensor(cx, math.batch('batch'), math.spatial('y, x')),\n",
    "            ], math.dual(vector=\"y,x\")\n",
    "            ) )\n",
    "\n",
    "            prediction += [ [domain.scalar_grid(marker_sim) , v_sim + v_corr] ]\n",
    "            correction += [ [domain.scalar_grid(marker_sim) , v_corr] ]\n",
    "\n",
    "        else: # only low-fidelity solver\n",
    "            prediction += [ [domain.scalar_grid(marker_sim) , v_sim ] ]\n",
    "\n",
    "        refs += [to_phiflow(targets[:,i,...])]\n",
    "        vdiff = prediction[i][1] - refs[-1]\n",
    "\n",
    "        error_phi = field.l1_loss(vdiff)\n",
    "        errors += [float( error_phi.native(\"batch\")[0] / field.l1_loss(refs[-1]).native(\"batch\")[0] )]\n",
    "\n",
    "    return errors, prediction, refs, correction\n"
   ],
   "id": "8e6eacadcb7190a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get a sample\n",
    "(input_cpu, targets_cpu) = next(iter(dataloader_test))\n",
    "input = torch.tensor(input_cpu, dtype=torch.float32).to(device)\n",
    "targets = torch.tensor(targets_cpu, dtype=torch.float32).to(device)\n",
    "print(\"Re \",math.tensor(input[0,3, 0,0].detach()))"
   ],
   "id": "9e55d63c932b981e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ROLLOUT_STEPS = 100\n",
    "\n",
    "err_lowfid_only, prediction_lowfid_only, refs, _   = run_sim(input, targets, ROLLOUT_STEPS)\n",
    "err_corrected,   prediction_corrected  , _ , corrs = run_sim(input, targets, ROLLOUT_STEPS, network)\n",
    "print(\"\\n Rel. L2 errors: low-fidelity:\", float(np.mean(err_lowfid_only)),\" corrected:\", float(np.mean(err_corrected)) )"
   ],
   "id": "ddfb304e0739ef41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = pylab.figure().gca()\n",
    "pltx = np.linspace(0,ROLLOUT_STEPS-1,ROLLOUT_STEPS)\n",
    "fig.plot(pltx, err_lowfid_only, lw=2, color='mediumblue', label='Source')\n",
    "fig.plot(pltx, err_corrected,   lw=2, color='green', label='Hybrid')\n",
    "pylab.xlabel('Time step'); pylab.ylabel('Relative L2 error'); fig.legend()\n"
   ],
   "id": "9da3e905df7f8fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# which step from which batch to show , by default shows last step from first case\n",
    "STEP = ROLLOUT_STEPS\n",
    "BATCH = 0\n",
    "NUM_SHOW = 4\n",
    "PRINT_STATS = False # optional, print statistics\n",
    "\n",
    "fig, axes = pylab.subplots(1, 4, figsize=(16, 5))\n",
    "i = 0\n",
    "\n",
    "v = refs[STEP].staggered_tensor().numpy('batch,y,x,vector')[BATCH,:,:,0]\n",
    "if PRINT_STATS: print([\"reference \", BATCH, i, np.mean(v),  np.min(v) ,  np.max(v)])\n",
    "axes[i].set_title(f\"Ref\")\n",
    "im=axes[i].imshow( v , origin='lower', cmap='magma') ;\n",
    "pylab.colorbar(im) ; i=i+1; vy_ref=v\n",
    "\n",
    "v = prediction_lowfid_only[STEP][1].staggered_tensor().numpy('batch,y,x,vector')[BATCH,:,:,0]\n",
    "if PRINT_STATS: print([\"low-fid. \", BATCH, i, np.mean(v),  np.min(v) ,  np.max(v)])\n",
    "axes[i].set_title(f\"Low-fid.\")\n",
    "im=axes[i].imshow( v , origin='lower', cmap='magma') ;\n",
    "pylab.colorbar(im) ; i=i+1; vy_lowfid=v\n",
    "\n",
    "v = prediction_corrected[STEP][1].staggered_tensor().numpy('batch,y,x,vector')[BATCH,:,:,0]\n",
    "if PRINT_STATS: print([\"corrected\", BATCH, i, np.mean(v),  np.min(v) ,  np.max(v)])\n",
    "axes[i].set_title(f\"Corr.\")\n",
    "im=axes[i].imshow( v , origin='lower', cmap='magma') ;\n",
    "pylab.colorbar(im) ; i=i+1; vy_corr=v\n",
    "\n",
    "# show error side by side\n",
    "err_lf   = vy_ref - vy_lowfid\n",
    "err_corr = vy_ref - vy_corr\n",
    "v = np.concatenate([err_lf,err_corr], axis=1)\n",
    "axes[i].set_title(f\" Errors: Low-fid & Learned\")\n",
    "im=axes[i].imshow( v , origin='lower', cmap='cividis') ;\n",
    "pylab.colorbar(im) ; i=i+1\n",
    "\n",
    "pylab.tight_layout()"
   ],
   "id": "117652e97ace63a8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
